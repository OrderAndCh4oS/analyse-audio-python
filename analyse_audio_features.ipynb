{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spectral Features\n",
    "\n",
    "Spectral features are a set of audio features that are derived from the spectral representation of an audio signal. The spectral representation of an audio signal is obtained by applying the Fourier transform to the signal over short time windows. This results in a time-varying representation of the signal in the frequency domain, where the power spectral density of the signal at different frequencies and time points is computed.\n",
    "\n",
    "The time-varying representation of the signal in the frequency domain means that the signal is analyzed over time at different frequencies. When an audio signal is transformed into the frequency domain using the Fourier transform, it becomes possible to see how much of the signal's energy is present at each frequency component.\n",
    "\n",
    "In this time-varying representation, the power spectral density of the signal is computed for different frequencies and time points. Power spectral density refers to the distribution of the signal's power across different frequencies. So, for each small time window, the power spectral density is computed for each frequency, resulting in a time-varying representation of the signal in the frequency domain.\n",
    "\n",
    "This representation allows for the extraction of various spectral features, which can be used to characterize different properties of the audio signal. By analyzing the spectral features over time, it is possible to gain insights into how the frequency content of the signal changes over time and how different events in the audio signal are related to changes in the spectral content."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:28:45.874273Z",
     "start_time": "2023-05-14T14:28:45.845253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_audio(audio_path):\n",
    "    x, sr = librosa.load(audio_path)\n",
    "    print(type(x), type(sr))\n",
    "    print(x.shape, sr)\n",
    "\n",
    "    return x, sr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:28:45.881395Z",
     "start_time": "2023-05-14T14:28:45.876633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'int'>\n",
      "(661794,) 22050\n"
     ]
    }
   ],
   "source": [
    "base_path = './Data/genres_original'\n",
    "file = 'reggae/reggae.00005.wav'\n",
    "audio_path = f'{base_path}/{file}'\n",
    "(y, sr) = load_audio(audio_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:28:50.700418Z",
     "start_time": "2023-05-14T14:28:45.883130Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chroma_stft\n",
    "\n",
    "A feature that represents the distribution of pitch classes in an audio signal. It is computed from the short-time Fourier transform (STFT) and can be used for tasks such as music genre classification and chord recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35166004, 0.28422588, 0.24786304, ..., 0.5592603 , 0.37255338,\n        0.78601134],\n       [0.688377  , 0.8210777 , 1.        , ..., 0.5851438 , 0.30033076,\n        0.64760494],\n       [1.        , 1.        , 0.8437313 , ..., 0.7478237 , 0.47217178,\n        0.7563511 ],\n       ...,\n       [0.8913222 , 0.58592093, 0.39343765, ..., 0.30214497, 0.2695208 ,\n        0.492628  ],\n       [0.84476644, 0.49521217, 0.36946237, ..., 0.29371986, 0.19176272,\n        0.3627578 ],\n       [0.2942005 , 0.19752395, 0.17520203, ..., 0.38606405, 0.20034434,\n        0.47595617]], dtype=float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.feature.chroma_stft(y=y, sr=sr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:29:06.267108Z",
     "start_time": "2023-05-14T14:29:06.120338Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use an energy (magnitude) spectrum instead of power spectrogram\n",
    "\n",
    "Using an energy (magnitude) spectrum instead of a power spectrogram means that instead of computing the power spectral density of the signal, the magnitude of the Short-Time Fourier Transform (STFT) is used.\n",
    "\n",
    "The STFT of an audio signal is obtained by computing the Fourier transform of short time windows of the signal. The resulting STFT consists of a time-varying complex-valued matrix whose magnitude is commonly used to represent the energy of the signal at each frequency and time point.\n",
    "\n",
    "In the following code snippet, the STFT of the audio signal 'y' is first computed using the librosa.stft() function, and the magnitude of the STFT is obtained using np.abs() function. Then, the chroma feature is computed from the magnitude spectrogram using the librosa.feature.chroma_stft() function.\n",
    "\n",
    "The chroma feature is a type of spectral feature that represents the pitch content of the audio signal. It is computed by mapping the STFT magnitude to a chromatic scale, which groups nearby frequencies into semitone bins. The resulting chroma feature is a time-varying matrix whose columns represent different pitch classes (e.g., C, C#, D, D#, etc.) and whose values represent the energy of the audio signal in each pitch class at each time point.\n",
    "\n",
    "Using the magnitude spectrogram instead of the power spectrogram can be beneficial in cases where only the relative magnitudes of different frequency components matter, and the exact power levels are less important. This approach can be particularly useful in music information retrieval tasks such as genre classification, chord recognition, and melody extraction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.53401726, 0.44683033, 0.4762849 , ..., 1.        , 0.96944803,\n        1.        ],\n       [0.81095344, 0.8673055 , 1.        , ..., 0.82923687, 0.66784894,\n        0.730963  ],\n       [0.8939466 , 1.        , 0.98646885, ..., 0.7671196 , 0.74128073,\n        0.69876546],\n       ...,\n       [0.9064403 , 0.7782171 , 0.7482533 , ..., 0.79530054, 0.6618843 ,\n        0.7130978 ],\n       [1.        , 0.85159045, 0.8512415 , ..., 0.81082565, 0.5449006 ,\n        0.61104953],\n       [0.600064  , 0.48774683, 0.48289582, ..., 0.90396106, 0.61699885,\n        0.68860346]], dtype=float32)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "S = np.abs(librosa.stft(y))\n",
    "chroma = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "chroma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:34:31.047755Z",
     "start_time": "2023-05-14T14:34:30.927631Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use a pre-computed power spectrogram with a larger frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.3437655 , 0.29820922, 0.25112718, ..., 0.5173068 , 0.52142656,\n        0.43685916],\n       [0.86834407, 1.        , 1.        , ..., 0.708154  , 0.5378942 ,\n        0.19122979],\n       [1.        , 0.83408046, 0.62090695, ..., 0.83584964, 0.6369374 ,\n        0.31624207],\n       ...,\n       [0.6932554 , 0.35709026, 0.07001977, ..., 0.47259486, 0.3459339 ,\n        0.24859168],\n       [0.5847085 , 0.3518466 , 0.18775363, ..., 0.35956472, 0.2758803 ,\n        0.23984511],\n       [0.21126698, 0.16427538, 0.14277802, ..., 0.39302167, 0.3452336 ,\n        0.30430454]], dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.abs(librosa.stft(y, n_fft=4096))**2\n",
    "chroma = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "chroma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:31:14.826603Z",
     "start_time": "2023-05-14T14:31:14.730801Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chroma_cqt\n",
    "\n",
    "Similar to chroma_stft, but computed using the constant-Q transform (CQT). It is more robust to tuning variations and can be used for music transcription."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chroma_cens\n",
    "\n",
    "A variant of chroma_stft that is computed using a constant energy normalization scheme (CENS). It is more robust to variations in tempo and dynamics and can be used for music recommendation and retrieval."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chroma_vqt\n",
    "\n",
    "A variant of chroma_cqt that is computed using a variable-Q transform (VQT). It is more suitable for analyzing non-stationary signals, such as speech and environmental sounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Melspectrogram\n",
    "\n",
    "A feature that represents the power spectral density of an audio signal in the mel-scale. It is computed using a bank of mel filters and can be used for speech recognition, speaker identification, and music genre classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MFCC\n",
    "\n",
    "Mel-frequency cepstral coefficients are a feature that represents the spectral envelope of an audio signal. They are computed by taking the logarithm of the mel-spectrum and applying a discrete cosine transform (DCT). They are commonly used for speech recognition and speaker identification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RMS\n",
    "\n",
    "Root mean square is a feature that represents the overall energy of an audio signal. It is computed as the square root of the average of the squared amplitude values and can be used for audio level normalization and loudness measurement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spectral_centroid\n",
    "\n",
    "A feature that represents the center of mass of the spectral distribution of an audio signal. It is computed as the weighted mean of the frequency values and can be used for timbre analysis and music genre classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spectral_bandwidth\n",
    "\n",
    "A feature that represents the width of the spectral distribution of an audio signal. It is computed as the second central moment of the frequency values and can be used for timbre analysis and music genre classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spectral_contrast\n",
    "\n",
    "A feature that represents the difference in energy between adjacent frequency bands of an audio signal. It is computed by dividing the spectrum into sub-bands and computing the difference between the maximum and minimum energy values in each band. It can be used for music genre classification and speech recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spectral_flatness\n",
    "\n",
    "A feature that represents the tonality of an audio signal. It is computed as the ratio between the geometric mean and the arithmetic mean of the power spectral density and can be used for music genre classification and instrument recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spectral_rolloff\n",
    "\n",
    "A feature that represents the frequency below which a certain percentage of the spectral energy of an audio signal is contained. It is computed as the frequency at which the cumulative sum of the spectral energy reaches a certain threshold and can be used for speech recognition and music genre classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Poly_features\n",
    "\n",
    "A feature that represents the coefficients of a polynomial fit to the magnitude spectrum of an audio signal. It is computed using linear regression and can be used for speech recognition and music genre classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tonnetz\n",
    "\n",
    "A feature that represents the harmonic relationships between pitch classes in an audio signal. It is computed using a graph-based representation and can be used for music analysis and chord recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
